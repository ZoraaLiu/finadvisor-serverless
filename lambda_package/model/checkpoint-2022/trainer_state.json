{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2022,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001483679525222552,
      "grad_norm": 0.2352989763021469,
      "learning_rate": 5e-05,
      "loss": 4.3922,
      "step": 1
    },
    {
      "epoch": 0.07418397626112759,
      "grad_norm": 0.3685228228569031,
      "learning_rate": 4.8788328387734914e-05,
      "loss": 4.3346,
      "step": 50
    },
    {
      "epoch": 0.14836795252225518,
      "grad_norm": 0.46172112226486206,
      "learning_rate": 4.7551928783382796e-05,
      "loss": 4.1265,
      "step": 100
    },
    {
      "epoch": 0.22255192878338279,
      "grad_norm": 0.5668487548828125,
      "learning_rate": 4.6315529179030666e-05,
      "loss": 3.8253,
      "step": 150
    },
    {
      "epoch": 0.29673590504451036,
      "grad_norm": 0.6653004288673401,
      "learning_rate": 4.5079129574678535e-05,
      "loss": 3.4821,
      "step": 200
    },
    {
      "epoch": 0.37091988130563797,
      "grad_norm": 0.5936203598976135,
      "learning_rate": 4.384272997032641e-05,
      "loss": 3.1917,
      "step": 250
    },
    {
      "epoch": 0.44510385756676557,
      "grad_norm": 0.6728793978691101,
      "learning_rate": 4.260633036597428e-05,
      "loss": 2.9336,
      "step": 300
    },
    {
      "epoch": 0.5192878338278932,
      "grad_norm": 0.7591292858123779,
      "learning_rate": 4.1369930761622164e-05,
      "loss": 2.6546,
      "step": 350
    },
    {
      "epoch": 0.5934718100890207,
      "grad_norm": 0.7292172908782959,
      "learning_rate": 4.013353115727003e-05,
      "loss": 2.3415,
      "step": 400
    },
    {
      "epoch": 0.6676557863501483,
      "grad_norm": 0.8365747332572937,
      "learning_rate": 3.88971315529179e-05,
      "loss": 2.1586,
      "step": 450
    },
    {
      "epoch": 0.7418397626112759,
      "grad_norm": 0.81321781873703,
      "learning_rate": 3.766073194856578e-05,
      "loss": 1.9199,
      "step": 500
    },
    {
      "epoch": 0.8160237388724035,
      "grad_norm": 3.5717272758483887,
      "learning_rate": 3.6424332344213655e-05,
      "loss": 1.7105,
      "step": 550
    },
    {
      "epoch": 0.8902077151335311,
      "grad_norm": 0.7934123277664185,
      "learning_rate": 3.5187932739861524e-05,
      "loss": 1.6189,
      "step": 600
    },
    {
      "epoch": 0.9643916913946587,
      "grad_norm": 1.0842913389205933,
      "learning_rate": 3.39515331355094e-05,
      "loss": 1.3784,
      "step": 650
    },
    {
      "epoch": 1.0385756676557865,
      "grad_norm": 0.8953220844268799,
      "learning_rate": 3.271513353115727e-05,
      "loss": 1.2742,
      "step": 700
    },
    {
      "epoch": 1.1127596439169138,
      "grad_norm": 1.5375192165374756,
      "learning_rate": 3.1478733926805146e-05,
      "loss": 1.1879,
      "step": 750
    },
    {
      "epoch": 1.1869436201780414,
      "grad_norm": 1.0946966409683228,
      "learning_rate": 3.024233432245302e-05,
      "loss": 1.1029,
      "step": 800
    },
    {
      "epoch": 1.2611275964391693,
      "grad_norm": 0.8659332990646362,
      "learning_rate": 2.900593471810089e-05,
      "loss": 1.0817,
      "step": 850
    },
    {
      "epoch": 1.3353115727002967,
      "grad_norm": 0.7944642305374146,
      "learning_rate": 2.7769535113748764e-05,
      "loss": 1.0314,
      "step": 900
    },
    {
      "epoch": 1.4094955489614243,
      "grad_norm": 0.8407357335090637,
      "learning_rate": 2.653313550939664e-05,
      "loss": 0.9776,
      "step": 950
    },
    {
      "epoch": 1.4836795252225519,
      "grad_norm": 0.8424979448318481,
      "learning_rate": 2.529673590504451e-05,
      "loss": 0.9071,
      "step": 1000
    },
    {
      "epoch": 1.5578635014836797,
      "grad_norm": 0.7341092228889465,
      "learning_rate": 2.4060336300692386e-05,
      "loss": 0.895,
      "step": 1050
    },
    {
      "epoch": 1.632047477744807,
      "grad_norm": 1.2017558813095093,
      "learning_rate": 2.282393669634026e-05,
      "loss": 0.8729,
      "step": 1100
    },
    {
      "epoch": 1.7062314540059347,
      "grad_norm": 0.934777557849884,
      "learning_rate": 2.158753709198813e-05,
      "loss": 0.8981,
      "step": 1150
    },
    {
      "epoch": 1.7804154302670623,
      "grad_norm": 0.859711766242981,
      "learning_rate": 2.0351137487636004e-05,
      "loss": 0.8423,
      "step": 1200
    },
    {
      "epoch": 1.8545994065281899,
      "grad_norm": 0.755089521408081,
      "learning_rate": 1.911473788328388e-05,
      "loss": 0.8111,
      "step": 1250
    },
    {
      "epoch": 1.9287833827893175,
      "grad_norm": 0.740367591381073,
      "learning_rate": 1.7878338278931753e-05,
      "loss": 0.7777,
      "step": 1300
    },
    {
      "epoch": 2.0029673590504453,
      "grad_norm": 0.7054561376571655,
      "learning_rate": 1.6641938674579626e-05,
      "loss": 0.7841,
      "step": 1350
    },
    {
      "epoch": 2.077151335311573,
      "grad_norm": 0.6425000429153442,
      "learning_rate": 1.54055390702275e-05,
      "loss": 0.7773,
      "step": 1400
    },
    {
      "epoch": 2.1513353115727005,
      "grad_norm": 0.8706400990486145,
      "learning_rate": 1.4169139465875373e-05,
      "loss": 0.7399,
      "step": 1450
    },
    {
      "epoch": 2.2255192878338277,
      "grad_norm": 0.9469262957572937,
      "learning_rate": 1.2932739861523244e-05,
      "loss": 0.7069,
      "step": 1500
    },
    {
      "epoch": 2.2997032640949557,
      "grad_norm": 0.603903591632843,
      "learning_rate": 1.1696340257171118e-05,
      "loss": 0.7336,
      "step": 1550
    },
    {
      "epoch": 2.373887240356083,
      "grad_norm": 0.8560329079627991,
      "learning_rate": 1.0459940652818991e-05,
      "loss": 0.7394,
      "step": 1600
    },
    {
      "epoch": 2.4480712166172105,
      "grad_norm": 0.7999986410140991,
      "learning_rate": 9.223541048466864e-06,
      "loss": 0.6689,
      "step": 1650
    },
    {
      "epoch": 2.5222551928783385,
      "grad_norm": 0.5993797183036804,
      "learning_rate": 7.987141444114738e-06,
      "loss": 0.7172,
      "step": 1700
    },
    {
      "epoch": 2.596439169139466,
      "grad_norm": 0.8922054171562195,
      "learning_rate": 6.750741839762611e-06,
      "loss": 0.7002,
      "step": 1750
    },
    {
      "epoch": 2.6706231454005933,
      "grad_norm": 0.7910714149475098,
      "learning_rate": 5.514342235410485e-06,
      "loss": 0.6435,
      "step": 1800
    },
    {
      "epoch": 2.744807121661721,
      "grad_norm": 0.6444240808486938,
      "learning_rate": 4.277942631058358e-06,
      "loss": 0.7194,
      "step": 1850
    },
    {
      "epoch": 2.8189910979228485,
      "grad_norm": 0.6967089772224426,
      "learning_rate": 3.0415430267062315e-06,
      "loss": 0.6955,
      "step": 1900
    },
    {
      "epoch": 2.893175074183976,
      "grad_norm": 0.5356400609016418,
      "learning_rate": 1.805143422354105e-06,
      "loss": 0.7147,
      "step": 1950
    },
    {
      "epoch": 2.9673590504451037,
      "grad_norm": 1.1015883684158325,
      "learning_rate": 5.687438180019782e-07,
      "loss": 0.6957,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 2022,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1510909446979584.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
